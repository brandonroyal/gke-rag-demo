{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.llms import HuggingFaceTextGenInference\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores.pgvector import PGVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A deployment in Kubernetes is a way to manage the lifecycle of a set of replicas of a pod. It allows you to specify the desired state of the deployment, including the number of replicas, the desired CPU and memory resources, and the container image to use. Kubernetes will then automatically manage the deployment, scaling it up or down as needed to meet the desired state. Deployments also provide rolling updates, which means that new versions of the pods are introduced gradually, with each new version replacing one of the old ones. This ensures that the application remains available during the update process.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test our Llama-2 interface with langchain\n",
    "\n",
    "llm = HuggingFaceTextGenInference(\n",
    "    inference_server_url=\"http://mistral-7b.broyal.demo/\",\n",
    "    max_new_tokens=512,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    typical_p=0.95,\n",
    "    temperature=0.01,\n",
    "    repetition_penalty=1.03,\n",
    ")\n",
    "llm(\"[INST] You are a helpful, respectful and honest assistant who is an expert in explaining Kubernetes concepts. Always answer as helpfully as possible, while being safe and keep your responses less than 200 words. What is a deployment?[/INST]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of URLs -> kubernetes.io/docs/concepts/\n",
    "file1 = open('./data/k8s-urls.samples.txt', 'r')\n",
    "\n",
    "loader = WebBaseLoader(file1.readlines())\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 chunks in 3 pages\n"
     ]
    }
   ],
   "source": [
    "# Chunk all the kubernetes concept documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(\"%s chunks in %s pages\" % (len(docs), len(documents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentence transformer embeddings\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\":\"cpu\"} # use {\"device\":\"cuda\"} for distributed embeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection string for connecting to Postgres\n",
    "CONNECTION_STRING = PGVector.connection_string_from_db_params(\n",
    "    driver=os.environ.get(\"PGVECTOR_DRIVER\", \"psycopg2\"),\n",
    "    host=os.environ.get(\"PGVECTOR_HOST\", \"localhost\"),\n",
    "    port=int(os.environ.get(\"PGVECTOR_PORT\", \"5432\")),\n",
    "    database=os.environ.get(\"PGVECTOR_DATABASE\", \"postgres\"),\n",
    "    user=os.environ.get(\"PGVECTOR_USER\", \"postgres\"),\n",
    "    password=os.environ.get(\"PGVECTOR_PASSWORD\", \"secretpassword\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"kubernetes_concepts-1\"\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=docs,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job.batch/indexer-job unchanged\n",
      "job.batch/test-job unchanged\n",
      "Name:             indexer-job\n",
      "Namespace:        default\n",
      "Selector:         batch.kubernetes.io/controller-uid=87b4e76c-72bb-4c0a-b03a-cce47878e1ff\n",
      "Labels:           job=indexer\n",
      "Annotations:      batch.kubernetes.io/job-tracking: \n",
      "Parallelism:      3\n",
      "Completions:      <unset>\n",
      "Completion Mode:  NonIndexed\n",
      "Start Time:       Tue, 31 Oct 2023 02:21:58 +0000\n",
      "Completed At:     Tue, 31 Oct 2023 02:22:58 +0000\n",
      "Duration:         60s\n",
      "Pods Statuses:    0 Active (0 Ready) / 3 Succeeded / 0 Failed\n",
      "Pod Template:\n",
      "  Labels:  batch.kubernetes.io/controller-uid=87b4e76c-72bb-4c0a-b03a-cce47878e1ff\n",
      "           batch.kubernetes.io/job-name=indexer-job\n",
      "           controller-uid=87b4e76c-72bb-4c0a-b03a-cce47878e1ff\n",
      "           job-name=indexer-job\n",
      "  Containers:\n",
      "   indexer-job:\n",
      "    Image:      gcr.io/broyal-llama-demo/llama-demo/indexer:0.1.7\n",
      "    Port:       <none>\n",
      "    Host Port:  <none>\n",
      "    Limits:\n",
      "      nvidia.com/gpu:  1\n",
      "    Environment:\n",
      "      PGVECTOR_HOST:        postgres\n",
      "      PUBSUB_SUBSCRIPTION:  kubernetes_concepts_subscription\n",
      "      COLLECTION_NAME:      kubernetes_concepts\n",
      "    Mounts:\n",
      "      /etc/secret-volume from secret-volume (ro)\n",
      "  Volumes:\n",
      "   secret-volume:\n",
      "    Type:        Secret (a volume populated by a Secret)\n",
      "    SecretName:  pubsub-svc\n",
      "    Optional:    false\n",
      "Events:\n",
      "  Type    Reason            Age   From            Message\n",
      "  ----    ------            ----  ----            -------\n",
      "  Normal  SuccessfulCreate  48m   job-controller  Created pod: indexer-job-vw7jw\n",
      "  Normal  SuccessfulCreate  48m   job-controller  Created pod: indexer-job-m82f9\n",
      "  Normal  SuccessfulCreate  48m   job-controller  Created pod: indexer-job-blr7d\n",
      "  Normal  Completed         47m   job-controller  Job completed\n",
      "No resources found in default namespace.\n",
      "---\n",
      "  seconds: 1698716512\n",
      "  nanos: 413000000\n",
      "}\n",
      "\n",
      "starting index of ['https://kubernetes.io/docs/concepts/windows/', 'https://kubernetes.io/docs/concepts/cluster-administration/addons/', 'https://kubernetes.io/docs/concepts/cluster-administration/flow-control/', 'https://kubernetes.io/docs/concepts/cluster-administration/proxies/', 'https://kubernetes.io/docs/concepts/cluster-administration/system-traces/']\n",
      "start: processing data\n",
      "159 chunks in 5 pages\n",
      "connectingn to vectordb. adding documents to kubernetes_concepts\n",
      "âŒ no messages in pub/sub\n",
      "ðŸ No more messages left in the queue. Shutting down...\n",
      "  seconds: 1698716522\n",
      "  nanos: 74000000\n",
      "}\n",
      "\n",
      "starting index of ['https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/', 'https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/', 'https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/', 'https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/']\n",
      "start: processing data\n",
      "126 chunks in 4 pages\n",
      "connectingn to vectordb. adding documents to kubernetes_concepts\n",
      "âŒ no messages in pub/sub\n",
      "ðŸ No more messages left in the queue. Shutting down...\n"
     ]
    }
   ],
   "source": [
    "# A better way with distributed jobs on Kubernetes\n",
    "! sh ./deploy-indexer.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Should I use gateway API in my app?\n",
      "Retrieved documents: 4\n",
      "Source:  https://kubernetes.io/docs/concepts/services-networking/service/\n",
      "\n",
      "Text:  cluster. An Ingress lets you consolidate your routing rules into a single resource, so\n",
      "that you can expose multiple components of your workload, running separately in your\n",
      "cluster, behind a single listener.The Gateway API for Kubernetes\n",
      "provides extra capabilities beyond Ingress and Service. You can add Gateway to your cluster -\n",
      "it is a family of extension APIs, implemented using\n",
      "CustomResourceDefinitions -\n",
      "and then use these to configure access to network services that are running in your cluster.Cloud-native service discoveryIf you're able to use Kubernetes APIs for service discovery in your application,\n",
      "you can query the API server\n",
      "for matching EndpointSlices. Kubernetes updates the EndpointSlices for a Service\n",
      "whenever the set of Pods in a Service changes.For non-native applications, Kubernetes offers ways to place a network port or load\n",
      "balancer in between your application and the backend Pods.Either way, your workload can use these service discovery \n",
      "\n",
      "Source:  https://kubernetes.io/docs/concepts/architecture/control-plane-node-communication/\n",
      "\n",
      "Text:  Advanced contributing\n",
      "Viewing Site Analytics\n",
      "Docs smoke test pageKubernetes DocumentationConceptsCluster ArchitectureCommunication between Nodes and the Control PlaneCommunication between Nodes and the Control PlaneThis document catalogs the communication paths between the API server\n",
      "and the Kubernetes cluster.\n",
      "The intent is to allow users to customize their installation to harden the network configuration\n",
      "such that the cluster can be run on an untrusted network (or on fully public IPs on a cloud\n",
      "provider).Node to Control PlaneKubernetes has a \"hub-and-spoke\" API pattern. All API usage from nodes (or the pods they run)\n",
      "terminates at the API server. None of the other control plane components are designed to expose\n",
      "remote services. The API server is configured to listen for remote connections on a secure HTTPS\n",
      "port (typically 443) with one or more forms of client\n",
      "authentication enabled.\n",
      "One or more forms of authorization should be\n",
      "enabled, especially if anonymous requests \n",
      "\n",
      "Source:  https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/\n",
      "\n",
      "Text:  is an ingress controller driving Kong Gateway.Kusk Gateway is an OpenAPI-driven ingress controller based on Envoy.The NGINX Ingress Controller for Kubernetes\n",
      "works with the NGINX webserver (as a proxy).The ngrok Kubernetes Ingress Controller is an open source controller for adding secure public access to your K8s services using the ngrok platform.The OCI Native Ingress Controller is an Ingress controller for Oracle Cloud Infrastructure which allows you to manage the OCI Load Balancer.The Pomerium Ingress Controller is based on Pomerium, which offers context-aware access policy.Skipper HTTP router and reverse proxy for service composition, including use cases like Kubernetes Ingress, designed as a library to build your custom proxy.The Traefik Kubernetes Ingress provider is an \n",
      "\n",
      "Source:  https://kubernetes.io/docs/concepts/services-networking/\n",
      "\n",
      "Text:  up networking for your cluster, and also provides an overview of the technologies involved.ServiceExpose an application running in your cluster behind a single outward-facing endpoint, even when the workload is split across multiple backends.IngressMake your HTTP (or HTTPS) network service available using a protocol-aware configuration mechanism, that understands web concepts like URIs, hostnames, paths, and more. The Ingress concept lets you map traffic to different backends based on rules you define via the Kubernetes API.Ingress ControllersIn order for an Ingress to work in your cluster, there must be an ingress controller running. You need to select at least one ingress controller and make sure it is set up in your cluster. This page lists common ingress controllers that you can deploy.EndpointSlicesThe EndpointSlice API is the mechanism that Kubernetes uses to let your Service scale to handle large numbers of backends, and allows the cluster to update its list of healthy backends \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Should I use gateway API in my app?\" # \"Should I use gateway API in my app?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Retrieved documents: {len(docs)}\")\n",
    "for doc in docs:\n",
    "    doc_details = doc.to_json()['kwargs']\n",
    "    print(\"Source: \", doc_details['metadata']['source'])\n",
    "    print(\"Text: \", doc_details['page_content'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template = \"\"\"[INST] You are a helpful, respectful and honest assistant who is an expert in explaining Kubernetes concepts. Always answer as helpfully as possible, while being safe.\n",
    "        Use the following pieces of context to answer the question. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "        \n",
    "        {context}\n",
    "\n",
    "        Question: {question}\n",
    "        Answer:[/INST]\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The Gateway API for Kubernetes provides extra capabilities beyond Ingress and Service. It allows you to configure access to network services that are running in your cluster. You can add Gateway to your cluster by implementing CustomResourceDefinitions, and then use these to configure access to network services.\n",
      "\n",
      "When deciding whether to use the Gateway API, you should consider the specific needs of your workload. If you need to expose multiple components of your workload behind a single listener, or if you need to configure access to network services in a more complex way than what can be done with Ingress and Service, then the Gateway API may be a good option.\n",
      "\n",
      "It's also worth noting that the Gateway API is still a relatively new and evolving feature in Kubernetes, so it may not be as well-documented or widely used as some of the other APIs. However, as the API continues to mature and become more widely adopted, it may become a more useful tool for managing access to network services in your cluster.\n"
     ]
    }
   ],
   "source": [
    "result = qa.run(\"When should I use the Gateway API?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the nation economic status? Summarize. Keep it under 200 words.\"\n",
    "test_rag(qa, query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
